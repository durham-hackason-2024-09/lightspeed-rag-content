# Metrics to monitor automation controller

Monitor your automation controller hosts at the system and application levels.
System level monitoring includes the following information:
* Disk I/O
* RAM use
* CPU use
* Network traffic
Application level metrics provide data that the application knows about the system. This data includes the following information:
* How many jobs are running in a given instance
* Capacity information about instances in the cluster
* How many inventories are present
* How many hosts are in those inventories
Using system and application metrics can help you identify what was happening in the application when a service degradation occurred. Information about automation controller's performance over time helps when diagnosing problems or doing capacity planning for future growth.

# Metrics for monitoring automation controller application

For application level monitoring, automation controller provides Prometheus-style metrics on an API endpoint /api/v2/metrics. Use these metrics to monitor aggregate data about job status and subsystem performance, such as for job output processing or job scheduling.

The metrics endpoint includes descriptions of each metric. Metrics of particular interest for performance include:

* awx_status_total
* Current total of jobs in each status. Helps correlate other events to activity in system.
* Can monitor upticks in errored or failed jobs.
* awx_instance_remaining_capacity
* Amount of capacity remaining for running additional jobs.
* callback_receiver_event_processing_avg_seconds
* colloquially called “job events lag”.
* Running average of the lag time between when a task occurred in ansible and when the user is able to see it. This indicates how far behind the callback receiver is in processing events. When this number is very high, users can consider scaling up the control plane or using the capacity adjustment feature to reduce the number of jobs a control node controls.
* callback_receiver_events_insert_db
* Counter of events that have been inserted by a node. Can be used to calculate the job event insertion rate over a given time period.
* callback_receiver_events_queue_size_redis
* Indicator of how far behind callback receiver is in processing events. If too high, Redis can cause the control node to run out of memory (OOM).

# System level monitoring

Monitoring the CPU and memory use of your cluster hosts is important because capacity management for instances does not introspect into the actual resource usage of hosts. The resource impact of automation jobs depends on what the playbooks are doing. For example, many cloud or networking modules do most of the processing on the execution node, which runs the Ansible Playbook. The impact on the automation controller is very different than if you were running a native module like “yum” where the work is performed on the target hosts where the execution node spends much of the time during this task waiting on results.

If CPU or memory usage is very high, consider lowering the capacity adjustment (available on the instance detail page) on affected instances in the automation controller. This limits how many jobs are run on or controlled by this instance.

Monitor the disk I/O and use of your system. The manner in which an automation controller node runs Ansible and caches output on the file system, and eventually saves it in the database, creates high levels of disk reads and writes. Identifying poor disk performance early can help prevent poor user experience and system degradation.

* For more information about configuring monitoring, see Metrics.
* Additional insights into automation usage are available when you enable data collection for automation analytics. For more information, see Automation analytics and Red Hat Insights for Red Hat Ansible Automation Platform.
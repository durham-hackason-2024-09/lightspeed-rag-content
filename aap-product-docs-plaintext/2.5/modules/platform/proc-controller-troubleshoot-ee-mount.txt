# Troubleshooting execution environment mount options

In some cases where the /etc/ssh/* files were added to the execution environment image due to customization of an execution environment, an SSH error can occur.
For example, exposing the /etc/ssh/ssh_config.d:/etc/ssh/ssh_config.d:O path enables the container to be mounted, but the ownership permissions are not mapped correctly.

Use the following procedure if you meet this error, or have upgraded from an older version of automation controller:

1. Change the container ownership on the mounted volume to root.
2. From the navigation panel, select menu:Settings[Job].
3. Click btn:[Edit].
4. Expose the path in the Paths to expose to isolated jobs field, using the current example:

[
  "/ssh_config:/etc/ssh/ssh_config.d/:0"
]

[NOTE]
----
The :O option is only supported for directories.
Be as detailed as possible, especially when specifying system paths.
Mounting /etc or /usr directly has an impact that makes it difficult to troubleshoot.
----

This informs Podman to run a command similar to the following example, where the configuration is mounted and the ssh command works as expected:

podman run -v /ssh_config:/etc/ssh/ssh_config.d/:O ...

To expose isolated paths in OpenShift or Kubernetes containers as HostPath, use the following configuration:

[
  "/mnt2:/mnt2",
  "/mnt3",
  "/mnt4:/mnt4:0"
]

Set Expose host paths for Container Groups to On to enable it.

When the playbook runs, the resulting Pod specification is similar to the following example.
Note the details of the volumeMounts and volumes sections.


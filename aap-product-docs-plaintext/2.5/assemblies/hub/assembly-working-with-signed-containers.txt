# Working with signed containers

Automation execution environments are container images used by Ansible automation controller to run jobs.
You can download this content to private automation hub, and publish it within your organization.

# Deploying your system for container signing

Automation hub implements image signing to offer better security for the execution environment container images.

To deploy your system so that it is ready for container signing, create a signing script.


[NOTE]
----
Installer looks for the script and key on the same server where installer is located.
----

1. From a terminal, create a signing script, and pass the script path as an installer parameter.

Example:

```
#!/usr/bin/env bash

# pulp_container SigningService will pass the next 4 variables to the script.
MANIFEST_PATH=$1
FINGERPRINT="$PULP_SIGNING_KEY_FINGERPRINT"
IMAGE_REFERENCE="$REFERENCE"
SIGNATURE_PATH="$SIG_PATH"

# Create container signature using skopeo
skopeo standalone-sign \
  $MANIFEST_PATH \
  $IMAGE_REFERENCE \
  $FINGERPRINT \
  --output $SIGNATURE_PATH

# Optionally pass the passphrase to the key if password protected.
# --passphrase-file /path/to/key_password.txt

# Check the exit status
STATUS=$?
if [ $STATUS -eq 0 ]; then
  echo {\"signature_path\": \"$SIGNATURE_PATH\"}
else
  exit $STATUS
fi
```

2. Review the Ansible Automation Platform installer inventory file for options for container signing that begin with automationhub_*.

```
[all:vars]
.
.
.

automationhub_create_default_container_signing_service = True
automationhub_container_signing_service_key = /absolute/path/to/key/to/sign
automationhub_container_signing_service_script = /absolute/path/to/script/that/signs
```

3. Once installation is complete, navigate to your automation hub.
4. From the navigation panel, select menu:MenuTopAC[Signature Keys].
5. Ensure that you have a key titled container-default, or container-anyname.


[NOTE]
----
The container-default service is created by the Ansible Automation Platform installer.
----

# Adding containers remotely to automation hub

You can add containers remotely to automation hub in one of the following two ways:

* Create Remotes
* Execution Environment

1. Log in to automation hub.
2. From the navigation panel, select menu:Automation Content[Remote Registries].
3. Click btn:[Add remote registry].
* In the Name field, enter the name of the registry where the container resides.
* In the URL field, enter the URL of the registry where the container resides.
* In the Username field, enter the username if necessary.
* In the Password field, enter the password if necessary.
* Click btn:[Save].

# Adding an execution environment

Automation execution environments are container images that make it possible to incorporate system-level dependencies and collection-based content.
Each execution environment allows you to have a customized image to run jobs, and each of them contain only what you need when running the job.

1. From the navigation panel, select menu:Automation Content[Execution Environments].
2. Click btn:[Add execution environment].
3. Enter the name of the execution environment.
4. Optional: Enter the upstream name.
5. Under Registry, select the name of the registry from the drop-down menu.
6. Enter tags in the Add tag(s) to include field.
If the field is blank, all the tags are passed.
You must specify which repository specific tags to pass.
7. The remaining fields are optional:
* Currently included tags
* Add tag(s) to exclude
* Currently excluded tag(s)
* Description
8. Click btn:[Save].
9. Synchronize the image.

# Pushing container images from your local environment

Use the following procedure to sign images on a local system and push those signed images to the automation hub registry.

1. From a terminal, log in to Podman, or any container client currently in use:

```
> podman pull <container-name>
```

2. After the image is pulled, add tags (for example: latest, rc, beta, or version numbers, such as 1.0; 2.3, and so on):

```
> podman tag <container-name> <server-address>/<container-name>:<tag name>
```

3. Sign the image after changes have been made, and push it back up to the automation hub registry:

```
> podman push <server-address>/<container-name>:<tag name> --tls-verify=false --sign-by <reference to the gpg key on your local>
```


If the image is not signed, it can only be pushed with any current signature embedded. Alternatively, you can use the following script to push the image without signing it:

```
> podman push <server-address>/<container-name>:<tag name> --tls-verify=false
```

4. Once the image has been pushed, navigate to your automation hub.
5. From the navigation panel, select menu:Automation Content[Execution Environments].
6. To display the new execution environment, click the Refresh icon.
7. Click the name of the image  to view your pushed image.

The details page in automation hub indicates whether or not an image has been signed. If the details page indicates that an image is Unsigned, you can sign the image from automation hub  using the following steps:

1. Click the image name to navigate to the details page.
2. Click the btn:[More Actions] icon &#8942;.
Three options are available:
* Use in Controller
* Delete
* Sign
3. Click Sign from the drop-down menu.

The signing service signs the image.
After the image is signed, the status changes to "signed".

# Policies with signed images

Policies can be used by podman or other image clients to ensure the validity of the image by assigning specific policies to that signature.

# Using podman to ensure an image is signed by a specific signature

When ensuring a signature is signed by specific signatures, the signature must be on your local environment.

1. From the navigation panel, select menu:MenuTopAC[Signature Keys].
2. Click the btn:[More Actions] icon &#8942; next to the signature that you are using.
3. Select Download key from the drop-down menu.
A new window opens.
4. In the Name field, enter the name of the key.
5. Click btn:[Save].

# Configuring the client to verify signatures

To ensure a container image pulled from the remote registry is properly signed, you must first configure the image with the proper public key in a policy file.

* The client must have sudo privileges configured to verify signatures.

1. Open your terminal and use the following command:

```
>  sudo <name of editor> /etc/containers/policy.json
```


The file that is displayed is similar to this:

```
{
  "default": [{"type": "reject"}],
  "transports": {
  	"docker": {
    	"quay.io": [{"type": "insecureAcceptAnything"}],
    	"docker.io": [{"type": "insecureAcceptAnything"}],
    	"<server-address>": [
      	{
          	    "type": "signedBy",
          	    "keyType": "GPGKeys",
          	    "keyPath": "/tmp/containersig.txt"
      	}]
  	}
  }
}
```


This file shows that neither quay.io, or docker.io will perform the verification, because the type is insecureAcceptAnything which overrides the default type of reject. However, <server-address> will perform the verification, because the parameter type is set to "signedBy".

[NOTE]
----
The only keyType currently supported is GPG keys.
----
2. Under the <server-address> entry, modify the keyPath <1> to include the
name of your key file.

```
{
    	"default": [{"type": "reject"}],
    	"transports": {
        	"docker": {
          	  "quay.io": [{"type": "insecureAcceptAnything"}],
          	  "docker.io": [{"type": "insecureAcceptAnything"}],
          	  "<server-address>": [{
                	"type": "signedBy",
                	"keyType": "GPGKeys",
                	"keyPath": "/tmp/<key file name>",
                	"signedIdentity": {
                  	  "type": "matchExact"
                    }
            	  }]
            }
    	}
}
```

3. Save and close the file.

* Pull the file using Podman, or your client of choice:


```
> podman pull <server-address>/<container-name>:<tag name> --tls-verify=false
```


This response verifies the image has been signed with no errors. If the image is not signed, the command fails.

* For more information about policy.json, see documentation for containers-policy.json.